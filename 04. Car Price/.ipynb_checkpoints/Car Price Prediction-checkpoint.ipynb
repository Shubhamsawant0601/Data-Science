{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e21c53",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries for ML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing Data\n",
    "\n",
    "df = pd.read_csv('car_data.csv')\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125212c8",
   "metadata": {},
   "source": [
    "# 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53294f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eda8ac",
   "metadata": {},
   "source": [
    "### As Model would not understand car name better as compare to numerical data hence we drop that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n",
    "       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c3e54",
   "metadata": {},
   "source": [
    "### To convert year as feature which impacts car price in inverse manner we find out the \"Age\" column which gives us age of car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "current_year = date.today().year\n",
    "\n",
    "df[\"Current_year\"] = current_year\n",
    "\n",
    "df[\"Age\"] = df[\"Current_year\"]-df[\"Year\"]\n",
    "\n",
    "df.drop([\"Year\", \"Current_year\"], axis=1, inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180cc35",
   "metadata": {},
   "source": [
    "###  OneHotEncoding for categorical features \n",
    "We use get_dummies() feature which utomatical converts all the categorical features to Encoded data.\n",
    "\n",
    "Use drop_first = True for dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Seller_Type\"].unique())\n",
    "print(df[\"Transmission\"].unique())\n",
    "print(df[\"Owner\"].unique())\n",
    "print(df[\"Fuel_Type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fdf871",
   "metadata": {},
   "source": [
    "### Finding the Correlation between the features\n",
    "\n",
    "- Here Green says high correlation and Red as low correlation \n",
    "- Features which are highely correlated with other features except Target are playing similar role and one them can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ec38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad0cf7",
   "metadata": {},
   "source": [
    "#### No features are highly correlated with other hence we can keep it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b26b59",
   "metadata": {},
   "source": [
    "### Feature Selection using ExtraTreesRegressor() \n",
    "We find out which features are highly important and which are not so important, here Owner feature is showig least importance hence we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "x = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "model=ExtraTreesRegressor()\n",
    "\n",
    "model.fit(x,y)\n",
    "\n",
    "feature_scores_df = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feature_scores_df = feature_scores_df.sort_values(ascending=False)\n",
    "feature_scores_df.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b8c98",
   "metadata": {},
   "source": [
    "#### Here We can Drop Owner feature as it is not playing much role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9069343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Owner\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe852d4",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "---------------------------------------------------\n",
    "# 2. Splitting Data into (Features, Target) and (Train, Test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7446ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57b8e5",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "------------------------------------------------------------\n",
    "# 3. Random Forest Regressor model for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72079073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27fee2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "First we perform RandomizedSearchCV and then Based on output of RandomizedSearchCV we perform GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6ce3d",
   "metadata": {},
   "source": [
    "#### Parameter grid for RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid = {'max_depth':  [int(x) for x in np.linspace(5,30,num=6)],\n",
    "             'max_features': ['auto', 'sqrt','log2', None],\n",
    "             'min_samples_leaf': [1, 2, 5, 10],\n",
    "             'min_samples_split' : [2, 5, 10, 15, 100],\n",
    "             'n_estimators' : [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n",
    "            }\n",
    "para_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e26dd6",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_cv = RandomizedSearchCV(estimator=rf, param_distributions=para_grid, scoring='neg_mean_squared_error', n_iter=10, cv=5, verbose=2, random_state=42)\n",
    "rf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = rf_cv.best_params_\n",
    "para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e7562",
   "metadata": {},
   "source": [
    "#### Parameter grid for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'max_depth': [para['max_depth']],\n",
    "    \n",
    "    'max_features': [None],\n",
    "    \n",
    "    'min_samples_leaf': [para['min_samples_leaf'], \n",
    "                         para['min_samples_leaf']+2, \n",
    "                         para['min_samples_leaf'] + 4],\n",
    "    \n",
    "    'min_samples_split': [para['min_samples_split'] - 2,\n",
    "                          para['min_samples_split'] - 1,\n",
    "                          para['min_samples_split'], \n",
    "                          para['min_samples_split'] +1,\n",
    "                          para['min_samples_split'] + 2],\n",
    "    \n",
    "    'n_estimators': [para['n_estimators'] - 200,\n",
    "                     para['n_estimators'] - 100, \n",
    "                     para['n_estimators'], \n",
    "                     para['n_estimators'] + 100, \n",
    "                     para['n_estimators'] + 200]\n",
    "}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405ffcb",
   "metadata": {},
   "source": [
    "#### GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d751f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_mean_squared_error',  cv=5, verbose=2)\n",
    "rf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85027d4",
   "metadata": {},
   "source": [
    "### Fitting Model on best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = rf_cv.best_params_\n",
    "\n",
    "rf_final = RandomForestRegressor(n_estimators = para[\"n_estimators\"],\n",
    "                                 min_samples_split = para[\"min_samples_split\"],\n",
    "                                 min_samples_leaf = para[\"min_samples_leaf\"],\n",
    "                                 max_features = None,\n",
    "                                 max_depth = para[\"max_depth\"])\n",
    "rf_final.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_final.predict(x_test)\n",
    "\n",
    "rf_final.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daff311",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d74b92",
   "metadata": {},
   "source": [
    "# Exporting Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec468514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "file = open(\"random_forest_regression_model.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(rf_final, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f4dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
